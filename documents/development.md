# CS 225 Data Structures
## Development (ahqiu2-pzy2-jvonahn2-merchia2)

##### April 18th to April 21st
The code was written to read the data from the csv file into a graph in **data_reader.h/cpp**. Useful structs and comparision functions to measure distance and compare location and distance were written in **encounter.h/cpp**. The KDTree from mp_mosaics was transfered over and adapted to be able to build off of a vector of encounter pointers, using the locations as node keys and the id number of the encounter as node values. This was done in **kdtree/point.h/hpp** and **kdtree/kdtree.h/cpp**. The make file was updated accordingly and test cases were written for each file in the tests directory. 

Additionally, code to run DFS/BFS traversals, in both **traversals.cpp** and **traversals.h**, was written. The traversals module takes in a vector of encounters and a starting point, and "sorts" the encounters by the order in which DFS or BFS would run through them. For example, BFS is expected to run through the encounters closer to the starting node first (breadth), while DFS is expected to run through the encounters farther from the starting node first (depth) before returning to the deepest unvisited node. A stack/queue was used to implement the DFS and BFS traversals, respectively, and testcases (**tests/test_traversals.cpp**) corresponding to the traversals were added.

#### April 23rd
During our weekly meeting we decided on slightly modifying our first and second algorithms. For our first algorithm, instead of finding the shortest path with the maximum number of encounters, we decided on just finding the shortest path between two nodes (as given by the distance) using Dijkstra's algorithm (since in our setting, the shortest path is going to most likely end up being unique). In addition, for our second "unique" algorithm, we chose to work on the betweeness centrality problem - we will run Dijkstra's on every possible starting point and use its shortest-path spanning tree to count the number of times a node is covered by a shortest path. Then we will display the nodes from the top N most visited nodes.


### April 30th
During our weekly meeting we made some more decisions on our second algorithm. We thought between using Floyd-Warshall for centrality, which is O(|V|^3), and running Dijkstra's once on each node, which is O(|E||V| + |V|^2 log|V|). We decided to work with Dijkstra's algorithm first, since we thought our encounter graph would be sparse (only a few neighbors per vertex) and would ultimately work better than Floyd-Warshall's. To do this, we needed to run Dijkstra's on each starting vertex once, and for each starting vertex, we wanted the path reconstruction from the selected start vertex to all the other verticies. We will create an adjacency list (of a vector of children for each parent node) to do this, and we will use this to create the betweeness centrality measure for each vertex, with respect to the particular starting vertex (by storing the sizes of the subtrees for each vertex, using recursion). Then, we will add the centralities for each starting vertex to get our final answer. We also discussed how to make the Dijkstra function signatures and also decided to add min-heap (for Dijkstra) and disjoint sets (for convenience, to check if two nodes are in the same connected component) for our implementation.
